{"cells":[{"cell_type":"markdown","metadata":{"id":"pvlfI8xdd7Bd"},"source":["# Imports"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TLgppzDld7Bh","executionInfo":{"status":"ok","timestamp":1671136244122,"user_tz":300,"elapsed":152,"user":{"displayName":"Rumi Allbert","userId":"15309551253174126837"}}},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torchvision\n","import os\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torchvision import datasets\n","import seaborn as sns\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","# from general import GeneralUtil as util"]},{"cell_type":"markdown","source":["## Constants"],"metadata":{"id":"skBg90-neRVr"}},{"cell_type":"code","source":["# Set the classes\n","classes = ('A', 'B', 'C', 'D', 'E')\n","# GPU Device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","ROOT_DIR='/content'"],"metadata":{"id":"7PAsmcaZeVc-","executionInfo":{"status":"ok","timestamp":1671136153531,"user_tz":300,"elapsed":1,"user":{"displayName":"Rumi Allbert","userId":"15309551253174126837"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDqBNR72d7Bi"},"source":["# Homebrewed Functions"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"EN7eN2p0d7Bj","executionInfo":{"status":"ok","timestamp":1671136159059,"user_tz":300,"elapsed":3,"user":{"displayName":"Rumi Allbert","userId":"15309551253174126837"}}},"outputs":[],"source":["def display_sample_image(imageloader, n=1):\n","    \"\"\"Display a sample of the images in the given image loader\"\"\"\n","    plt.rcParams[\"figure.figsize\"] = (10, 10)\n","\n","    def _imshow(img):\n","        img = img / 2 + 0.5  # unnormalize\n","        npimg = img.numpy()\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","        plt.show()\n","\n","    for _ in range(n):\n","        # get some random images\n","        dataiter = iter(imageloader)\n","        images, labels = next(dataiter)\n","\n","        # show images\n","        _imshow(torchvision.utils.make_grid(images))\n","        # print labels\n","        print(\" \".join(\"%12s\" % classes[labels[j]] for j in range(len(images))))\n","\n","\n","def plot_acc_loss(train_accs, test_accs, train_losses, test_losses, caption):\n","    \"\"\"Plot the accuracy and loss\"\"\"\n","    # Visualize the loss / acc\n","    plt.figure()\n","    plt.plot(train_accs, label=\"Train\")\n","    plt.plot(test_accs, label=\"Test\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend()\n","    plt.title(\"Classification Accuracy vs Epoch: {}\".format(caption))\n","\n","    # Visualize the loss / acc\n","    plt.figure()\n","    plt.plot(train_losses, label=\"Train\")\n","    plt.plot(test_losses, label=\"Test\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Cross Entropy Loss\")\n","    plt.legend()\n","    plt.title(\"Cross Entropy Loss vs Epoch: {}\".format(caption))\n","\n","    return\n","\n","\n","def plot_confusion_matrix(y_true, y_pred):\n","    \"\"\"Plot the confusion matrix\"\"\"\n","    cm = confusion_matrix(y_true, y_pred)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","    disp.plot()\n","    plt.show()\n","\n","\n","def train(device=torch.device(\"cpu\"), scheduler=None):\n","    \"\"\"Function to train the model\"\"\"\n","    net.train()\n","\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for i, data in enumerate(train_loader, 0):\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs.to(device))\n","        loss = criterion(outputs, labels.to(device))\n","        loss.backward()\n","        optimizer.step()\n","\n","        if scheduler:\n","            scheduler.step()\n","\n","        # Calcualte accuracy\n","        _, predicted = torch.max(outputs.data.detach().cpu(), 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","\n","    training_loss.append(running_loss / i)\n","    training_acc.append(100.0 * correct / total)\n","\n","    return running_loss\n","\n","\n","def validation(val_loader, device=torch.device(\"cpu\"), verbose=False):\n","    actual = []\n","    pred = []\n","\n","    correct = 0\n","    total = 0\n","    running_loss = 0.0\n","    net.eval()\n","\n","    # prepare to count predictions for each class\n","    correct_pred = {classname: 0 for classname in classes}\n","    total_pred = {classname: 0 for classname in classes}\n","\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        for data in val_loader:\n","            images, labels = data\n","            # calculate outputs by running images through the network\n","            outputs = net(images.to(device))\n","\n","            loss = criterion(outputs, labels.to(device))\n","            running_loss += loss.item()\n","\n","            # the class with the highest energy is what we choose as prediction\n","            _, predicted = torch.max(outputs.data.detach().cpu(), 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            # collect the correct predictions for each class\n","            for label, prediction in zip(labels, predicted):\n","                if verbose:\n","                    actual.append(label.item())\n","                    pred.append(prediction.item())\n","                if label == prediction:\n","                    correct_pred[classes[label]] += 1\n","                total_pred[classes[label]] += 1\n","\n","    if verbose:\n","        print(\"==\" * 30)\n","        print(f\"Accuracy of the network on the test images: {100 * correct / total}%\")\n","        print(\"==\" * 30)\n","        # print accuracy for each class\n","        for classname, correct_count in correct_pred.items():\n","            accuracy = 100 * float(correct_count) / total_pred[classname]\n","            print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))\n","        print(\"==\" * 30)\n","        plot_confusion_matrix(actual, pred)\n","\n","    if not verbose:\n","        val_acc.append(100.0 * correct / total)\n","        val_loss.append(running_loss / len(val_loader))\n","\n","    return running_loss / len(val_loader)\n","\n","\n","def save_model(net, PATH=f\"{ROOT_DIR}/models/\", name=\"asl_cnn.pth\"):\n","    \"\"\"Function to save the model\"\"\"\n","    torch.save(net.state_dict(), PATH + name)"]},{"cell_type":"markdown","metadata":{"id":"lYma38Nld7Bl"},"source":["# Download Test Images"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mEouJmfTd7Bl","executionInfo":{"status":"ok","timestamp":1671136495739,"user_tz":300,"elapsed":948,"user":{"displayName":"Rumi Allbert","userId":"15309551253174126837"}},"outputId":"f3dd0a1e-8d3a-4ad8-e822-359739413107"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-15 20:34:55--  https://github.com/RumiAllbert/American-Sign-Language-Recogniztion-CNN/raw/main/images/R.A.testing_img.zip\n","Resolving github.com (github.com)... 140.82.113.3\n","Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/RumiAllbert/American-Sign-Language-Recogniztion-CNN/main/images/R.A.testing_img.zip [following]\n","--2022-12-15 20:34:55--  https://raw.githubusercontent.com/RumiAllbert/American-Sign-Language-Recogniztion-CNN/main/images/R.A.testing_img.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 97988 (96K) [application/zip]\n","Saving to: ‘/content/test/testing_img.zip’\n","\n","/content/test/testi 100%[===================>]  95.69K  --.-KB/s    in 0.01s   \n","\n","2022-12-15 20:34:55 (8.91 MB/s) - ‘/content/test/testing_img.zip’ saved [97988/97988]\n","\n","Archive:  /content/test/testing_img.zip\n","   creating: /content/test/R.A.testing_img/\n","  inflating: /content/test/__MACOSX/._R.A.testing_img  \n","  inflating: /content/test/R.A.testing_img/.DS_Store  \n","  inflating: /content/test/__MACOSX/R.A.testing_img/._.DS_Store  \n","  inflating: /content/test/R.A.testing_img/R.A.A01.jpg  \n","  inflating: /content/test/__MACOSX/R.A.testing_img/._R.A.A01.jpg  \n","  inflating: /content/test/R.A.testing_img/R.A.C01.jpg  \n","  inflating: /content/test/__MACOSX/R.A.testing_img/._R.A.C01.jpg  \n","  inflating: /content/test/R.A.testing_img/R.A.E01.jpg  \n","  inflating: /content/test/__MACOSX/R.A.testing_img/._R.A.E01.jpg  \n","  inflating: /content/test/R.A.testing_img/R.A.B01.jpg  \n","  inflating: /content/test/__MACOSX/R.A.testing_img/._R.A.B01.jpg  \n","  inflating: /content/test/R.A.testing_img/R.A.D01.jpg  \n","  inflating: /content/test/__MACOSX/R.A.testing_img/._R.A.D01.jpg  \n"]}],"source":["# Prepare dir\n","!mkdir /content/test/\n","\n","# Fetch\n","!wget https://github.com/RumiAllbert/American-Sign-Language-Recogniztion-CNN/raw/main/images/R.A.testing_img.zip -O /content/test/testing_img.zip\n","\n","# Unzip\n","!unzip /content/test/testing_img.zip -d /content/test"]},{"cell_type":"markdown","metadata":{"id":"5odvvk9cd7Bm"},"source":["# Load Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ajNlbK-Id7Bm"},"outputs":[],"source":["!wget https://github.com/RumiAllbert/American-Sign-Language-Recogniztion-CNN/blob/main/models/sgd_nd_tuned_asl_cnn.pth -O asl_cnn_model.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OI3tQPP2d7Bn"},"outputs":[],"source":["train_loader, val_loader, test_loader = load_data(TRAINING_PATH, TESTING_PATH, batch_size=15)\n","PATH = f'{ROOT_DIR}/models/sgd_tuned_asl_cnn.pth'\n","\n","net = ASL_CNN(num_classes=5, dropout=0.25)\n","# Loss function\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=.001, momentum=0.9)\n","\n","net.load_state_dict(torch.load(PATH))\n","net.to(device)\n","# net = load_model(net, name='adam200_tuned_asl_cnn.pth')\n","\n","validation(test_loader, device=device, verbose=True)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0bf1fd3e7175d64031801ff00c26ae563216f10a4267130d566bf09957a280ea"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}